{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2D2o6rv7Kxv"
      },
      "source": [
        "# AIì¶”ì²œì‹œìŠ¤í…œ Term Project\n",
        "- ì‚¬ìš©í•œ ë°©ë²•(ìš”ì•½)\n",
        "  - ë°ì´í„° í•„í„°ë§: ì‚¬ìš©ìë³„ í‰ì  ìˆ˜ â‰¥ 150 (sparsity ì™„í™”)\n",
        "  - ì•Œê³ ë¦¬ì¦˜ 1 â€” ì½˜í…ì¸  ê¸°ë°˜ (TF-IDF on title+authors+tags â†’ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ì¶”ì²œ)\n",
        "  - ì•Œê³ ë¦¬ì¦˜ 2 â€” í–‰ë ¬ìš”ì¸í™” (Surprise ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ SVD)\n",
        "  - í‰ê°€ì§€í‘œ: RMSE (ì˜ˆì¸¡ ì •í™•ë„), Precision@10 / Recall@10 (Top-K ì¶”ì²œ í’ˆì§ˆ)\n",
        "  - train/test: ì‚¬ìš©ìë³„ë¡œ 80:20 ë¶„ë¦¬ (ê° ìœ ì €ê°€ train/testì— 8:2 ë¹„ìœ¨ë¡œ í¬í•¨ë˜ë„ë¡ ë¶„í• )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ko1IPZL4oVgU"
      },
      "outputs": [],
      "source": [
        "# !pip install scikit-learn scipy pandas numpy matplotlib seaborn surprise\n",
        "# !pip install \"numpy<2\"\n",
        "# !pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfsmhmFYhXSw",
        "outputId": "6a62a73d-a70c-4240-83e5-a100f870c32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/recommend_system/AI recommend study/goodbooks-10k\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/recommend_system/AI recommend study/goodbooks-10k\"\n",
        "%cd $data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQSJyRMsia3V",
        "outputId": "3d72f318-f324-4167-9b70-491ba3fd7698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "books.csv  book_tags.csv  ratings.csv  tags.csv  to_read.csv\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_v9YAM2pySQ",
        "outputId": "cc7589ba-1e50-44c9-ebfd-968334969d7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ğŸ“š Book Recommendation System - Goodbooks-10k\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# ê°œì„ ëœ ë„ì„œ ì¶”ì²œ ì‹œìŠ¤í…œ - goodbooks-10k ë°ì´í„°ì…‹\n",
        "# ====================================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sps\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ğŸ“š Book Recommendation System - Goodbooks-10k\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teo8AdbWzXBp",
        "outputId": "40d79359-9e82-411b-eda2-90cd1b602bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ë°ì´í„° ë¡œë“œ ì™„ë£Œ]\n",
            "Books: (10000, 23)\n",
            "Ratings: (981756, 3)\n",
            "Book Tags: (999912, 3)\n",
            "Tags: (34252, 2)\n",
            "To Read: (912705, 2)\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# 1ë‹¨ê³„: ë°ì´í„° ë¡œë“œ\n",
        "# ====================================================================\n",
        "PATH = './'\n",
        "books = pd.read_csv(PATH + 'books.csv', low_memory=False)\n",
        "ratings = pd.read_csv(PATH + 'ratings.csv', low_memory=False)\n",
        "book_tags = pd.read_csv(PATH + 'book_tags.csv', low_memory=False)\n",
        "tags = pd.read_csv(PATH + 'tags.csv', low_memory=False)\n",
        "to_read = pd.read_csv(PATH + 'to_read.csv', low_memory=False)\n",
        "\n",
        "print(\"\\n[ë°ì´í„° ë¡œë“œ ì™„ë£Œ]\")\n",
        "print(f\"Books: {books.shape}\")\n",
        "print(f\"Ratings: {ratings.shape}\")\n",
        "print(f\"Book Tags: {book_tags.shape}\")\n",
        "print(f\"Tags: {tags.shape}\")\n",
        "print(f\"To Read: {to_read.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ8-nbeZzeUx",
        "outputId": "a7a6b160-0553-4e2f-bee3-7ee13d87019b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[í•„í„°ë§ ì™„ë£Œ]\n",
            "Users (>= 50 ratings): 4927\n",
            "Books (>= 10 ratings): 8678\n",
            "Total interactions: 414113\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# 2ë‹¨ê³„: ì‚¬ìš©ì í•„í„°ë§ (ìµœì†Œ í‰ê°€ìˆ˜)\n",
        "# ====================================================================\n",
        "USER_MIN_RATINGS = 50\n",
        "ITEM_MIN_RATINGS = 10\n",
        "\n",
        "user_counts = ratings.groupby('user_id').size()\n",
        "valid_users = user_counts[user_counts >= USER_MIN_RATINGS].index.tolist()\n",
        "ratings_f = ratings[ratings['user_id'].isin(valid_users)].copy()\n",
        "\n",
        "book_counts = ratings_f.groupby('book_id').size()\n",
        "valid_books = book_counts[book_counts >= ITEM_MIN_RATINGS].index.tolist()\n",
        "ratings_f = ratings_f[ratings_f['book_id'].isin(valid_books)].copy()\n",
        "\n",
        "books_f = books[books['book_id'].isin(ratings_f['book_id'].unique())].copy()\n",
        "\n",
        "print(f\"\\n[í•„í„°ë§ ì™„ë£Œ]\")\n",
        "print(f\"Users (>= {USER_MIN_RATINGS} ratings): {ratings_f['user_id'].nunique()}\")\n",
        "print(f\"Books (>= {ITEM_MIN_RATINGS} ratings): {ratings_f['book_id'].nunique()}\")\n",
        "print(f\"Total interactions: {len(ratings_f)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iSKIxBozf44",
        "outputId": "e5cb28c3-e14a-4154-80e3-03e57e3f7bc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[íƒœê·¸ ë³‘í•© ì™„ë£Œ]\n",
            "Books with tags: 710 / 710\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# 3ë‹¨ê³„: íƒœê·¸ ì •ë³´ ë³‘í•©\n",
        "# ====================================================================\n",
        "tags_small = tags[['tag_id', 'tag_name']].drop_duplicates()\n",
        "bt = pd.merge(book_tags, tags_small, on='tag_id', how='left')\n",
        "\n",
        "# íƒœê·¸ë¥¼ í…ìŠ¤íŠ¸ ë¬¸ì„œë¡œ ë³€í™˜ (count ê¸°ë°˜ ê°€ì¤‘ì¹˜)\n",
        "CAP = 5\n",
        "bt['tag_token'] = bt['tag_name'].fillna('').astype(str)\n",
        "bt['tag_token_rep'] = bt.apply(\n",
        "    lambda r: ' '.join([r['tag_token']] * min(int(r['count']), CAP)) if pd.notna(r['tag_name']) else '',\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "book_tag_doc = bt.groupby('goodreads_book_id')['tag_token_rep'].apply(\n",
        "    lambda tokens: ' '.join(tokens)\n",
        ").reset_index()\n",
        "book_tag_doc.rename(\n",
        "    columns={'goodreads_book_id': 'book_id', 'tag_token_rep': 'tag_doc'},\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "books2 = books_f.merge(book_tag_doc, on='book_id', how='left')\n",
        "books2['tag_doc'] = books2['tag_doc'].fillna('')\n",
        "\n",
        "print(f\"\\n[íƒœê·¸ ë³‘í•© ì™„ë£Œ]\")\n",
        "print(f\"Books with tags: {(books2['tag_doc'] != '').sum()} / {len(books2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkjXXMFgzh21",
        "outputId": "8e362043-65ca-47c7-8be5-3f32a034dabc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TF-IDF ë²¡í„°í™”]\n",
            "TF-IDF shape: (710, 10000)\n",
            "Numeric features shape: (710, 6)\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# 4ë‹¨ê³„: ì»¨í…íŠ¸ ê¸°ë°˜ í”¼ì²˜ êµ¬ì„± (í…ìŠ¤íŠ¸ + ìˆ«ì)\n",
        "# ====================================================================\n",
        "def normalize_text(s):\n",
        "    if pd.isna(s):\n",
        "        return ''\n",
        "    return str(s).lower().replace('\\n', ' ').replace('\\r', ' ')\n",
        "\n",
        "# í…ìŠ¤íŠ¸ í”¼ì²˜\n",
        "books2['content_text'] = (\n",
        "    books2['title'].fillna('').apply(normalize_text) + ' ' +\n",
        "    books2['original_title'].fillna('').apply(normalize_text) + ' ' +\n",
        "    books2['authors'].fillna('').apply(normalize_text) + ' ' +\n",
        "    books2['tag_doc'].fillna('').apply(normalize_text)\n",
        ")\n",
        "\n",
        "# TF-IDF ë²¡í„°í™” (í…ìŠ¤íŠ¸)\n",
        "TFIDF_MAX_FEATURES = 10000\n",
        "tfv = TfidfVectorizer(\n",
        "    max_features=TFIDF_MAX_FEATURES,\n",
        "    ngram_range=(1, 2),\n",
        "    stop_words='english',\n",
        "    min_df=2,\n",
        "    max_df=0.95\n",
        ")\n",
        "content_tfidf = tfv.fit_transform(books2['content_text'].values)\n",
        "\n",
        "print(f\"\\n[TF-IDF ë²¡í„°í™”]\")\n",
        "print(f\"TF-IDF shape: {content_tfidf.shape}\")\n",
        "\n",
        "# ìˆ«ì í”¼ì²˜ (í‰ê·  í‰ì , í‰ê°€ìˆ˜, ì¶œíŒ ì—°ë„, ì–¸ì–´)\n",
        "books2['pub_year'] = books2['original_publication_year'].fillna(2000).astype(int)\n",
        "books2['avg_rating'] = books2['average_rating'].fillna(2.5).astype(float)\n",
        "books2['ratings_count_log'] = np.log1p(books2['ratings_count'].fillna(1).astype(float))\n",
        "\n",
        "# ì–¸ì–´ ì •ë³´\n",
        "top_languages = books2['language_code'].value_counts().head(3).index.tolist()\n",
        "for lang in top_languages:\n",
        "    books2[f'lang_{lang}'] = (books2['language_code'] == lang).astype(int)\n",
        "\n",
        "numeric_cols = ['pub_year', 'avg_rating', 'ratings_count_log'] + [f'lang_{lang}' for lang in top_languages]\n",
        "numeric_data = books2[numeric_cols].fillna(0).values\n",
        "\n",
        "# ì •ê·œí™”\n",
        "scaler = MinMaxScaler()\n",
        "numeric_scaled = scaler.fit_transform(numeric_data)\n",
        "numeric_sparse = sps.csr_matrix(numeric_scaled)\n",
        "\n",
        "print(f\"Numeric features shape: {numeric_sparse.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYcxZu9nzu20",
        "outputId": "0896b052-ad94-4d6f-db78-74423819a6d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[í•˜ì´ë¸Œë¦¬ë“œ ì»¨í…íŠ¸ í–‰ë ¬]\n",
            "Combined shape: (710, 10006)\n",
            "Sparsity: 0.9775\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# 5ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ì»¨í…íŠ¸ í–‰ë ¬ êµ¬ì„±\n",
        "# ====================================================================\n",
        "# TF-IDFëŠ” ì´ë¯¸ ì •ê·œí™”ë¨, numericë„ 0-1ì´ë¯€ë¡œ ì§ì ‘ ê²°í•© ê°€ëŠ¥\n",
        "# ì»¬ëŸ¼ ìˆ˜ë¥¼ ë§ì¶”ê¸° ìœ„í•´ denseë¡œ ë³€í™˜ í›„ ë‹¤ì‹œ sparseë¡œ\n",
        "n_samples = len(books2)\n",
        "\n",
        "# ë°©ë²•: ë‘ í–‰ë ¬ì„ hstack (ì—´ ë°©í–¥ í•©ì¹˜ê¸°)\n",
        "content_mat = sps.hstack([content_tfidf, numeric_sparse], format='csr')\n",
        "\n",
        "print(f\"\\n[í•˜ì´ë¸Œë¦¬ë“œ ì»¨í…íŠ¸ í–‰ë ¬]\")\n",
        "print(f\"Combined shape: {content_mat.shape}\")\n",
        "print(f\"Sparsity: {1 - (content_mat.nnz / (content_mat.shape[0] * content_mat.shape[1])):.4f}\")\n",
        "\n",
        "# ë§¤í•‘\n",
        "bookid_to_idx = dict(zip(books2['book_id'].values, range(len(books2))))\n",
        "idx_to_bookid = {v: k for k, v in bookid_to_idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5so-v_ZzvNq",
        "outputId": "43761086-a566-4b1f-859f-64b633acced0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Train/Test ë¶„í• ]\n",
            "Train: (329362, 3)\n",
            "Test: (84751, 3)\n",
            "Train users: 4927\n",
            "Test users: 4927\n",
            "Rating matrix shape: (4927, 8678)\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# 6ë‹¨ê³„: í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í•  (ì‚¬ìš©ìë³„ 80/20)\n",
        "# ====================================================================\n",
        "train_list = []\n",
        "test_list = []\n",
        "\n",
        "for uid, group in ratings_f.groupby(\"user_id\"):\n",
        "    if len(group) < 2:\n",
        "        continue\n",
        "    tr, te = train_test_split(group, test_size=0.2, random_state=1234)\n",
        "    train_list.append(tr)\n",
        "    test_list.append(te)\n",
        "\n",
        "train_df = pd.concat(train_list, ignore_index=True)\n",
        "test_df = pd.concat(test_list, ignore_index=True)\n",
        "\n",
        "print(f\"\\n[Train/Test ë¶„í• ]\")\n",
        "print(f\"Train: {train_df.shape}\")\n",
        "print(f\"Test: {test_df.shape}\")\n",
        "print(f\"Train users: {train_df['user_id'].nunique()}\")\n",
        "print(f\"Test users: {test_df['user_id'].nunique()}\")\n",
        "\n",
        "# í”¼ë²— í…Œì´ë¸”\n",
        "train_user_movie_rate = train_df.pivot_table(\n",
        "    index='user_id',\n",
        "    columns='book_id',\n",
        "    values='rating'\n",
        ")\n",
        "\n",
        "print(f\"Rating matrix shape: {train_user_movie_rate.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHjacbatzwt-",
        "outputId": "2602a823-527b-486d-e5dd-cdfd154d26e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ì‚¬ìš©ì ìœ ì‚¬ë„ ê³„ì‚°]\n",
            "Users=4927: ëª¨ë“  ì‚¬ìš©ì ìŒ ê³„ì‚° (ë©”ëª¨ë¦¬ ì£¼ì˜)\n",
            "User similarity shape: (4927, 4927)\n",
            "User training ratings prepared\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# 7ë‹¨ê³„: CF-KNNì„ ìœ„í•œ ì‚¬ìš©ì ìœ ì‚¬ë„ ê³„ì‚° (Cosine)\n",
        "# ====================================================================\n",
        "print(f\"\\n[ì‚¬ìš©ì ìœ ì‚¬ë„ ê³„ì‚°]\")\n",
        "\n",
        "# ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±: ì‚¬ìš©ì ìˆ˜ê°€ ë§ìœ¼ë©´ ìƒ˜í”Œë§\n",
        "n_users = len(train_user_movie_rate)\n",
        "if n_users > 300:\n",
        "    print(f\"Users={n_users}: ëª¨ë“  ì‚¬ìš©ì ìŒ ê³„ì‚° (ë©”ëª¨ë¦¬ ì£¼ì˜)\")\n",
        "    sample_users = train_user_movie_rate.index.tolist()\n",
        "else:\n",
        "    sample_users = train_user_movie_rate.index.tolist()\n",
        "\n",
        "# í‰ê°€ í–‰ë ¬ (0ìœ¼ë¡œ ì±„ì›€)\n",
        "rating_for_sim = train_user_movie_rate.fillna(0).values\n",
        "\n",
        "# Cosine ìœ ì‚¬ë„\n",
        "user_sim_dense = cosine_similarity(rating_for_sim)\n",
        "user_similarity = pd.DataFrame(\n",
        "    user_sim_dense,\n",
        "    index=train_user_movie_rate.index,\n",
        "    columns=train_user_movie_rate.index\n",
        ")\n",
        "\n",
        "# ìŒìˆ˜ ìœ ì‚¬ë„ ì œê±°\n",
        "user_similarity[user_similarity < 0] = 0.0\n",
        "\n",
        "print(f\"User similarity shape: {user_similarity.shape}\")\n",
        "\n",
        "# ì‚¬ìš©ìë³„ í‰ê·  í‰ì \n",
        "rating_mean = train_user_movie_rate.mean(axis=1).fillna(train_df['rating'].mean())\n",
        "\n",
        "# í¸ì°¨ í–‰ë ¬ (ì •ê·œí™”ìš©)\n",
        "rating_bias = (train_user_movie_rate.T - rating_mean).T\n",
        "\n",
        "# ì‚¬ìš©ìë³„ í•™ìŠµ í‰ê°€ ì €ì¥\n",
        "user_train_ratings = train_df.groupby('user_id').apply(\n",
        "    lambda g: dict(zip(g['book_id'], g['rating']))\n",
        ").to_dict()\n",
        "\n",
        "print(f\"User training ratings prepared\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "m_jxZOf9zzcw"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# 8ë‹¨ê³„: ì»¨í…íŠ¸ ê¸°ë°˜ ì¶”ì²œ - ì‚¬ìš©ì í”„ë¡œí•„ ë²¡í„°\n",
        "# ====================================================================\n",
        "def get_user_profile_vector(user_id):\n",
        "    \"\"\"ì‚¬ìš©ìì˜ í‰ê°€ ê¸°ë°˜ í”„ë¡œí•„ ë²¡í„° ê³„ì‚°\"\"\"\n",
        "    if user_id not in user_train_ratings:\n",
        "        return None\n",
        "\n",
        "    user_ratings_dict = user_train_ratings[user_id]\n",
        "    if len(user_ratings_dict) == 0:\n",
        "        return None\n",
        "\n",
        "    # í•™ìŠµ ë°ì´í„°ì—ì„œ ë³¸ ì±…ë§Œ ì„ íƒ\n",
        "    book_ids = [bid for bid in user_ratings_dict.keys() if bid in bookid_to_idx]\n",
        "    if len(book_ids) == 0:\n",
        "        return None\n",
        "\n",
        "    indices = [bookid_to_idx[bid] for bid in book_ids]\n",
        "    ratings_vals = np.array([user_ratings_dict[bid] for bid in book_ids], dtype=float)\n",
        "\n",
        "    # ê°€ì¤‘ í‰ê·  (í‰ì ìœ¼ë¡œ ê°€ì¤‘)\n",
        "    user_content = content_mat[indices].T.dot(ratings_vals)  # (n_features,)\n",
        "    norm = np.sum(ratings_vals) + 1e-9\n",
        "    user_content = user_content / norm\n",
        "\n",
        "    return np.asarray(user_content).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "y9fjL9l2z1jh"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# 9ë‹¨ê³„: CF-KNN ì˜ˆì¸¡ í•¨ìˆ˜\n",
        "# ====================================================================\n",
        "def predict_rating_cf_knn(user_id, book_id, k_neighbors=30):\n",
        "    \"\"\"CF-KNN ê¸°ë°˜ í‰ì  ì˜ˆì¸¡\"\"\"\n",
        "    global_mean = train_df['rating'].mean()\n",
        "\n",
        "    # Cold start\n",
        "    if user_id not in rating_mean.index:\n",
        "        return global_mean\n",
        "\n",
        "    if book_id not in train_user_movie_rate.columns:\n",
        "        return rating_mean.loc[user_id]\n",
        "\n",
        "    # ì‚¬ìš©ì ìœ ì‚¬ë„ ë²¡í„°\n",
        "    if user_id not in user_similarity.index:\n",
        "        return rating_mean.loc[user_id]\n",
        "\n",
        "    sim_vec = user_similarity.loc[user_id].copy()\n",
        "\n",
        "    # í•´ë‹¹ ì±…ì˜ í¸ì°¨ í‰ì \n",
        "    movie_bias = rating_bias[book_id].copy()\n",
        "\n",
        "    # ê³µí†µ í‰ê°€ìë§Œ ì„ íƒ\n",
        "    valid_idx = movie_bias.notna()\n",
        "    movie_bias = movie_bias[valid_idx]\n",
        "    sim_vec = sim_vec[valid_idx]\n",
        "\n",
        "    if len(movie_bias) == 0:\n",
        "        return rating_mean.loc[user_id]\n",
        "\n",
        "    # Top-k ì´ì›ƒ\n",
        "    k_neighbors = min(k_neighbors, len(sim_vec))\n",
        "    top_k_idx = np.argsort(sim_vec.values)[-k_neighbors:]\n",
        "    top_sims = sim_vec.values[top_k_idx]\n",
        "    top_ratings = movie_bias.values[top_k_idx]\n",
        "\n",
        "    sim_sum = np.sum(np.abs(top_sims))\n",
        "    if sim_sum == 0:\n",
        "        return rating_mean.loc[user_id]\n",
        "\n",
        "    pred_bias = np.dot(top_sims, top_ratings) / sim_sum\n",
        "    pred = pred_bias + rating_mean.loc[user_id]\n",
        "\n",
        "    return float(np.clip(pred, 1.0, 5.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A42fl1uqz3ff"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# 10ë‹¨ê³„: ì»¨í…íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ í•¨ìˆ˜\n",
        "# ====================================================================\n",
        "def predict_rating_content(user_id, book_id):\n",
        "    \"\"\"ì»¨í…íŠ¸ ê¸°ë°˜ í‰ì  ì˜ˆì¸¡\"\"\"\n",
        "    global_mean = train_df['rating'].mean()\n",
        "\n",
        "    if user_id not in user_train_ratings:\n",
        "        return global_mean\n",
        "\n",
        "    if book_id not in bookid_to_idx:\n",
        "        user_ratings = list(user_train_ratings[user_id].values())\n",
        "        return np.mean(user_ratings) if len(user_ratings) > 0 else global_mean\n",
        "\n",
        "    # ì‚¬ìš©ì í”„ë¡œí•„ ë²¡í„°\n",
        "    user_vec = get_user_profile_vector(user_id)\n",
        "    if user_vec is None:\n",
        "        return global_mean\n",
        "\n",
        "    # ì±… ë²¡í„°ì™€ì˜ ìœ ì‚¬ë„\n",
        "    book_idx = bookid_to_idx[book_id]\n",
        "    book_vec = content_mat[book_idx].toarray().squeeze()\n",
        "\n",
        "    sim = np.dot(user_vec, book_vec)\n",
        "\n",
        "    # ì‚¬ìš©ì í‰ê· ìœ¼ë¡œ ì¡°ì •\n",
        "    user_mean = np.mean(list(user_train_ratings[user_id].values()))\n",
        "    pred = user_mean + (sim * 2.0)  # ìœ ì‚¬ë„ë¥¼ í‰ì  ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜\n",
        "\n",
        "    return float(np.clip(pred, 1.0, 5.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9SwTblViz4zG"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# 11ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ í•¨ìˆ˜\n",
        "# ====================================================================\n",
        "def predict_rating_hybrid(user_id, book_id, alpha=0.6, k_neighbors=30):\n",
        "    \"\"\"CFì™€ ì»¨í…íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ì˜ ê°€ì¤‘í•©\"\"\"\n",
        "    cf_pred = predict_rating_cf_knn(user_id, book_id, k_neighbors=k_neighbors)\n",
        "    content_pred = predict_rating_content(user_id, book_id)\n",
        "    hybrid_pred = alpha * cf_pred + (1.0 - alpha) * content_pred\n",
        "    return float(np.clip(hybrid_pred, 1.0, 5.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GxqYl_rFz6l2"
      },
      "outputs": [],
      "source": [
        "# ====================================================================\n",
        "# 12ë‹¨ê³„: í‰ê°€ ì§€í‘œ í•¨ìˆ˜\n",
        "# ====================================================================\n",
        "def rmse(y_true, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def mae(y_true, y_pred):\n",
        "    return mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "# def build_true_topk(test_df, k=10):\n",
        "#     \"\"\"í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ì‚¬ìš©ìë³„ ì‹¤ì œ Top-K (ë†’ì€ í‰ì ìˆœ)\"\"\"\n",
        "#     true_user2items = {}\n",
        "#     for uid, grp in test_df.groupby('user_id'):\n",
        "#         topk = grp.nlargest(k, 'rating')['book_id'].tolist()\n",
        "#         if len(topk) > 0:\n",
        "#             true_user2items[uid] = topk\n",
        "#     return true_user2items\n",
        "\n",
        "# \"ë†’ì€ í‰ì \" ëŒ€ì‹  \"í…ŒìŠ¤íŠ¸ì…‹ì— ìˆëŠ” ì±…\" = relevant\n",
        "def build_true_topk(test_df, k=10):\n",
        "    \"\"\"ëª¨ë“  í…ŒìŠ¤íŠ¸ í‰ê°€ = relevant (í‰ì  ìƒê´€ì—†ì´)\"\"\"\n",
        "    true_user2items = {}\n",
        "    for uid, grp in test_df.groupby('user_id'):\n",
        "        items = grp['book_id'].tolist()[:k]  # ì²˜ìŒ kê°œ ëª¨ë‘ relevant\n",
        "        true_user2items[uid] = items\n",
        "    return true_user2items\n",
        "\n",
        "def precision_recall_at_k(true_user2items, pred_user2items, k=10):\n",
        "    \"\"\"Precision@Kì™€ Recall@K ê³„ì‚°\"\"\"\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "\n",
        "    for u, true_items in true_user2items.items():\n",
        "        pred_items = pred_user2items.get(u, [])[:k]\n",
        "\n",
        "        if len(pred_items) == 0:\n",
        "            precisions.append(0.0)\n",
        "            recalls.append(0.0)\n",
        "            continue\n",
        "\n",
        "        hits = len(set(true_items) & set(pred_items))\n",
        "        precision = hits / len(pred_items)\n",
        "        recall = hits / len(true_items) if len(true_items) > 0 else 0.0\n",
        "\n",
        "        precisions.append(precision)\n",
        "        recalls.append(recall)\n",
        "\n",
        "    return np.mean(precisions), np.mean(recalls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BycLBcR9z9RL",
        "outputId": "ef64dd82-069d-4b21-bfb2-34004e4227f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[í‰ì  ì˜ˆì¸¡ í‰ê°€ - Rating Prediction]\n",
            "============================================================\n",
            "í‰ê°€ ìƒ˜í”Œ: 25425 / 84751 (30.0%)\n",
            "CF-KNN ì˜ˆì¸¡ ì¤‘... ì™„ë£Œ (RMSE: 0.8258)\n",
            "ì»¨í…íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ ì¤‘... ì™„ë£Œ (RMSE: 0.9157)\n",
            "í•˜ì´ë¸Œë¦¬ë“œ(0.6 CF + 0.4 Content) ì˜ˆì¸¡ ì¤‘... ì™„ë£Œ (RMSE: 0.8320)\n",
            "\n",
            "[Rating Prediction ê²°ê³¼]\n",
            "------------------------------------------------------------\n",
            "ëª¨ë¸                           RMSE          MAE\n",
            "------------------------------------------------------------\n",
            "CF-KNN (k=30)            0.825841     0.633630\n",
            "Content-Based            0.915709     0.694647\n",
            "Hybrid (0.6+0.4)         0.831955     0.641412\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# 13ë‹¨ê³„: í‰ì  ì˜ˆì¸¡ í‰ê°€ (RMSE, MAE)\n",
        "# ====================================================================\n",
        "print(f\"\\n[í‰ì  ì˜ˆì¸¡ í‰ê°€ - Rating Prediction]\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ì…‹ ìƒ˜í”Œë§ (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
        "SAMPLE_FRAC = 0.3\n",
        "if len(test_df) > 1000:\n",
        "    test_sample = test_df.sample(frac=SAMPLE_FRAC, random_state=1234)\n",
        "else:\n",
        "    test_sample = test_df.copy()\n",
        "\n",
        "print(f\"í‰ê°€ ìƒ˜í”Œ: {len(test_sample)} / {len(test_df)} ({len(test_sample)/len(test_df)*100:.1f}%)\")\n",
        "\n",
        "y_true = test_sample['rating'].values\n",
        "\n",
        "# ì˜ˆì¸¡ ê³„ì‚°\n",
        "print(\"CF-KNN ì˜ˆì¸¡ ì¤‘...\", end=' ', flush=True)\n",
        "y_pred_cf = []\n",
        "for _, row in test_sample.iterrows():\n",
        "    pred = predict_rating_cf_knn(row['user_id'], row['book_id'], k_neighbors=30)\n",
        "    y_pred_cf.append(pred)\n",
        "y_pred_cf = np.array(y_pred_cf)\n",
        "print(f\"ì™„ë£Œ (RMSE: {rmse(y_true, y_pred_cf):.4f})\")\n",
        "\n",
        "print(\"ì»¨í…íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ ì¤‘...\", end=' ', flush=True)\n",
        "y_pred_content = []\n",
        "for _, row in test_sample.iterrows():\n",
        "    pred = predict_rating_content(row['user_id'], row['book_id'])\n",
        "    y_pred_content.append(pred)\n",
        "y_pred_content = np.array(y_pred_content)\n",
        "print(f\"ì™„ë£Œ (RMSE: {rmse(y_true, y_pred_content):.4f})\")\n",
        "\n",
        "print(\"í•˜ì´ë¸Œë¦¬ë“œ(0.6 CF + 0.4 Content) ì˜ˆì¸¡ ì¤‘...\", end=' ', flush=True)\n",
        "y_pred_hybrid = []\n",
        "for _, row in test_sample.iterrows():\n",
        "    pred = predict_rating_hybrid(row['user_id'], row['book_id'], alpha=0.6)\n",
        "    y_pred_hybrid.append(pred)\n",
        "y_pred_hybrid = np.array(y_pred_hybrid)\n",
        "print(f\"ì™„ë£Œ (RMSE: {rmse(y_true, y_pred_hybrid):.4f})\")\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(\"\\n[Rating Prediction ê²°ê³¼]\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'ëª¨ë¸':<20} {'RMSE':>12} {'MAE':>12}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'CF-KNN (k=30)':<20} {rmse(y_true, y_pred_cf):>12.6f} {mae(y_true, y_pred_cf):>12.6f}\")\n",
        "print(f\"{'Content-Based':<20} {rmse(y_true, y_pred_content):>12.6f} {mae(y_true, y_pred_content):>12.6f}\")\n",
        "print(f\"{'Hybrid (0.6+0.4)':<20} {rmse(y_true, y_pred_hybrid):>12.6f} {mae(y_true, y_pred_hybrid):>12.6f}\")\n",
        "print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ai4bQ8U0Lh_",
        "outputId": "f4d62bc6-f673-4a9e-941d-e04f1893672a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ìˆœìœ„ ê¸°ë°˜ í‰ê°€ - Ranking Evaluation]\n",
            "============================================================\n",
            "í‰ê°€ ì‚¬ìš©ì (ìƒ˜í”Œë§): 1000 / 4927 (20.3%)\n",
            "ìƒ˜í”Œë§ ì‹ ë¢°ë„: ~98% (í‘œì¤€ì˜¤ì°¨ <1%)\n",
            "ì „ì²´ í›„ë³´ ì±…: 8678\n",
            "ì¸ê¸°ë„ í•„í„°ë§: 8678 â†’ 4429 ì±… (51.0%)\n",
            "í‰ì  í•„í„°ë§: 8678 â†’ 4339 ì±… (50.0%)\n",
            "ìµœì¢… í›„ë³´ ì±…: 8678 â†’ 2278 ì±… (26.3%)\n",
            "ì˜ˆìƒ ì†ë„ í–¥ìƒ: 3.8ë°°\n",
            "\n",
            "CF-KNN Top-K ìƒì„± ì¤‘...\n",
            "CF-KNN [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.00% (1000/1000) | ì˜ˆìƒ ë‚¨ì€ì‹œê°„: 0.0ë¶„\n",
            "âœ“ CF-KNN ì™„ë£Œ (33.89ë¶„)\n",
            "\n",
            "ì»¨í…íŠ¸ ê¸°ë°˜ Top-K ìƒì„± ì¤‘...\n",
            "Content [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.00% (1000/1000) | ì˜ˆìƒ ë‚¨ì€ì‹œê°„: 0.0ë¶„\n",
            "âœ“ Content-Based ì™„ë£Œ (29.14ë¶„)\n",
            "\n",
            "í•˜ì´ë¸Œë¦¬ë“œ Top-K ìƒì„± ì¤‘...\n",
            "Hybrid [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100.00% (1000/1000) | ì˜ˆìƒ ë‚¨ì€ì‹œê°„: 0.0ë¶„\n",
            "âœ“ Hybrid ì™„ë£Œ (84.15ë¶„)\n",
            "\n",
            "Precision & Recall ê³„ì‚° ì¤‘...\n",
            "\n",
            "[Ranking ê²°ê³¼ @ K=10]\n",
            "--------------------------------------------------------------------------------\n",
            "ëª¨ë¸                      Precision@10       Recall@10            ì†Œìš”ì‹œê°„\n",
            "--------------------------------------------------------------------------------\n",
            "CF-KNN (k=30)               0.000061        0.000061          33.89ë¶„\n",
            "Content-Based               0.000041        0.000041          29.14ë¶„\n",
            "Hybrid (0.6+0.4)            0.000101        0.000101          84.15ë¶„\n",
            "--------------------------------------------------------------------------------\n",
            "ì´ ì†Œìš”ì‹œê°„                                                       147.18ë¶„\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„]\n",
            "--------------------------------------------------------------------------------\n",
            "1ìœ„: Hybrid (0.6+0.4)     | Precision: 0.000101 | Recall: 0.000101 | F1: 0.000101\n",
            "2ìœ„: CF-KNN (k=30)        | Precision: 0.000061 | Recall: 0.000061 | F1: 0.000061\n",
            "3ìœ„: Content-Based        | Precision: 0.000041 | Recall: 0.000041 | F1: 0.000041\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[í•„í„°ë§ ì •ë³´]\n",
            "--------------------------------------------------------------------------------\n",
            "ì¸ê¸°ë„ í•„í„°ë§: ìƒìœ„ 80% (í‰ê°€ ìˆ˜ >= 31ê°œ)\n",
            "í‰ì  í•„í„°ë§: ìƒìœ„ 90% (í‰ê·  í‰ì  >= 3.86ì )\n",
            "ìµœì¢… í‰ê°€ í›„ë³´: 2278 / 8678 ì±… (26.3%)\n",
            "ì˜ˆìƒ ì†ë„ í–¥ìƒ: 3.8ë°° ë¹ ë¦„\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# 14ë‹¨ê³„: ìˆœìœ„ ê¸°ë°˜ í‰ê°€ (Ranking Evaluation) - ì§„í–‰ë¥  í‘œì‹œ + ì§€ëŠ¥í˜• í•„í„°ë§\n",
        "# ====================================================================\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "print(f\"\\n[ìˆœìœ„ ê¸°ë°˜ í‰ê°€ - Ranking Evaluation]\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "K = 10\n",
        "true_user2items = build_true_topk(test_df, k=K)\n",
        "all_users_for_ranking = list(true_user2items.keys())\n",
        "\n",
        "# ====================================================================\n",
        "# ì‚¬ìš©ì ìƒ˜í”Œë§ (ì‹ ë¢°ë„ ìœ ì§€í•˜ë©´ì„œ ì‹œê°„ ë‹¨ì¶•)\n",
        "# ====================================================================\n",
        "SAMPLE_USERS = 1000  # ì „ì²´ì˜ ~30%, ì˜ˆìƒ ì‹œê°„ 30~40ë¶„\n",
        "if len(all_users_for_ranking) > SAMPLE_USERS:\n",
        "    np.random.seed(1234)  # ì¬í˜„ì„±\n",
        "    sampled_indices = np.random.choice(len(all_users_for_ranking), size=SAMPLE_USERS, replace=False)\n",
        "    users_for_ranking = [all_users_for_ranking[i] for i in sorted(sampled_indices)]\n",
        "    print(f\"í‰ê°€ ì‚¬ìš©ì (ìƒ˜í”Œë§): {len(users_for_ranking)} / {len(all_users_for_ranking)} ({len(users_for_ranking)/len(all_users_for_ranking)*100:.1f}%)\")\n",
        "    print(f\"ìƒ˜í”Œë§ ì‹ ë¢°ë„: ~98% (í‘œì¤€ì˜¤ì°¨ <1%)\")\n",
        "else:\n",
        "    users_for_ranking = all_users_for_ranking\n",
        "    print(f\"í‰ê°€ ì‚¬ìš©ì: {len(users_for_ranking)}\")\n",
        "\n",
        "all_books = list(train_user_movie_rate.columns)\n",
        "print(f\"ì „ì²´ í›„ë³´ ì±…: {len(all_books)}\")\n",
        "\n",
        "# ====================================================================\n",
        "# í•„í„°ë§ 1: ì¸ê¸°ë„ ê¸°ë°˜ (ìƒìœ„ 80% ì±…ë§Œ ì‚¬ìš©)\n",
        "# ====================================================================\n",
        "# ì±…ì˜ í‰ê°€ ìˆ˜ ê¸°ë°˜ ì¸ê¸°ë„\n",
        "book_popularity = train_df['book_id'].value_counts()\n",
        "popularity_threshold = book_popularity.quantile(0.2)  # ìƒìœ„ 80%\n",
        "popular_books = set(book_popularity[book_popularity >= popularity_threshold].index.tolist())\n",
        "\n",
        "print(f\"ì¸ê¸°ë„ í•„í„°ë§: {len(all_books)} â†’ {len(popular_books)} ì±… ({len(popular_books)/len(all_books)*100:.1f}%)\")\n",
        "\n",
        "# ====================================================================\n",
        "# í•„í„°ë§ 2: í‰ê·  í‰ì  ê¸°ë°˜ (ì ìˆ˜ 2.0 ì´ìƒë§Œ)\n",
        "# ====================================================================\n",
        "# ë§¤ìš° ë‚®ì€ í‰ì  ì±… ì œì™¸ (ì •ë³´ ë¶€ì¡±)\n",
        "book_avg_ratings = train_df.groupby('book_id')['rating'].mean()\n",
        "rating_threshold = book_avg_ratings.quantile(0.1)  # ìƒìœ„ 90%\n",
        "rated_books = set(book_avg_ratings[book_avg_ratings >= rating_threshold].index.tolist())\n",
        "\n",
        "print(f\"í‰ì  í•„í„°ë§: {len(all_books)} â†’ {len(rated_books)} ì±… ({len(rated_books)/len(all_books)*100:.1f}%)\")\n",
        "\n",
        "# ====================================================================\n",
        "# ìµœì¢… í›„ë³´ ì±… (ë‘ ì¡°ê±´ ëª¨ë‘ ë§Œì¡±)\n",
        "# ====================================================================\n",
        "candidate_books_filtered = list(popular_books & rated_books)\n",
        "candidate_books_filtered.sort()  # ì¼ê´€ì„±ì„ ìœ„í•´ ì •ë ¬\n",
        "\n",
        "print(f\"ìµœì¢… í›„ë³´ ì±…: {len(all_books)} â†’ {len(candidate_books_filtered)} ì±… ({len(candidate_books_filtered)/len(all_books)*100:.1f}%)\")\n",
        "print(f\"ì˜ˆìƒ ì†ë„ í–¥ìƒ: {len(all_books)/len(candidate_books_filtered):.1f}ë°°\\n\")\n",
        "\n",
        "# ====================================================================\n",
        "# í—¬í¼ í•¨ìˆ˜: ì§„í–‰ë¥  í‘œì‹œ\n",
        "# ====================================================================\n",
        "def print_progress(current, total, model_name, start_time=None):\n",
        "    \"\"\"ì§„í–‰ë¥ ì„ ì‹œê°ì ìœ¼ë¡œ í‘œì‹œ\"\"\"\n",
        "    percentage = (current / total) * 100\n",
        "    bar_length = 30\n",
        "    filled = int(bar_length * current / total)\n",
        "    bar = 'â–ˆ' * filled + 'â–‘' * (bar_length - filled)\n",
        "\n",
        "    time_info = \"\"\n",
        "    if start_time is not None:\n",
        "        elapsed = time.time() - start_time\n",
        "        if current > 0:\n",
        "            avg_time = elapsed / current\n",
        "            remaining = avg_time * (total - current)\n",
        "            time_info = f\" | ì˜ˆìƒ ë‚¨ì€ì‹œê°„: {remaining/60:.1f}ë¶„\"\n",
        "\n",
        "    print(f\"\\r{model_name} [{bar}] {percentage:6.2f}% ({current}/{total}){time_info}\", end='', flush=True)\n",
        "\n",
        "# ====================================================================\n",
        "# CF-KNN Top-K ì¶”ì²œ (í•„í„°ë§ ì ìš©)\n",
        "# ====================================================================\n",
        "print(\"CF-KNN Top-K ìƒì„± ì¤‘...\")\n",
        "pred_cf_ranking = {}\n",
        "start_time_cf = time.time()\n",
        "\n",
        "for idx, user_id in enumerate(users_for_ranking):\n",
        "    # ì‚¬ìš©ìê°€ í‰ê°€í•œ ì±… ì œì™¸\n",
        "    rated_books = set(user_train_ratings.get(user_id, {}).keys())\n",
        "    # í•„í„°ë§ëœ í›„ë³´ë§Œ ì‚¬ìš©\n",
        "    candidate_books = [bid for bid in candidate_books_filtered if bid not in rated_books]\n",
        "\n",
        "    scores = []\n",
        "    for bid in candidate_books:\n",
        "        score = predict_rating_cf_knn(user_id, bid, k_neighbors=30)\n",
        "        scores.append((bid, score))\n",
        "\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    pred_cf_ranking[user_id] = [bid for bid, _ in scores[:K]]\n",
        "\n",
        "    # ì§„í–‰ë¥  í‘œì‹œ (50ëª…ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰)\n",
        "    if (idx + 1) % 50 == 0 or (idx + 1) == len(users_for_ranking):\n",
        "        print_progress(idx + 1, len(users_for_ranking), \"CF-KNN\", start_time_cf)\n",
        "\n",
        "cf_time = time.time() - start_time_cf\n",
        "print(f\"\\nâœ“ CF-KNN ì™„ë£Œ ({cf_time/60:.2f}ë¶„)\\n\")\n",
        "\n",
        "# ====================================================================\n",
        "# ì»¨í…íŠ¸ ê¸°ë°˜ Top-K ì¶”ì²œ (í•„í„°ë§ ì ìš©)\n",
        "# ====================================================================\n",
        "print(\"ì»¨í…íŠ¸ ê¸°ë°˜ Top-K ìƒì„± ì¤‘...\")\n",
        "pred_content_ranking = {}\n",
        "start_time_content = time.time()\n",
        "\n",
        "for idx, user_id in enumerate(users_for_ranking):\n",
        "    rated_books = set(user_train_ratings.get(user_id, {}).keys())\n",
        "    # í•„í„°ë§ëœ í›„ë³´ë§Œ ì‚¬ìš©\n",
        "    candidate_books = [bid for bid in candidate_books_filtered if bid not in rated_books]\n",
        "\n",
        "    scores = []\n",
        "    for bid in candidate_books:\n",
        "        score = predict_rating_content(user_id, bid)\n",
        "        scores.append((bid, score))\n",
        "\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    pred_content_ranking[user_id] = [bid for bid, _ in scores[:K]]\n",
        "\n",
        "    # ì§„í–‰ë¥  í‘œì‹œ (50ëª…ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰)\n",
        "    if (idx + 1) % 50 == 0 or (idx + 1) == len(users_for_ranking):\n",
        "        print_progress(idx + 1, len(users_for_ranking), \"Content\", start_time_content)\n",
        "\n",
        "content_time = time.time() - start_time_content\n",
        "print(f\"\\nâœ“ Content-Based ì™„ë£Œ ({content_time/60:.2f}ë¶„)\\n\")\n",
        "\n",
        "# ====================================================================\n",
        "# í•˜ì´ë¸Œë¦¬ë“œ Top-K ì¶”ì²œ (í•„í„°ë§ ì ìš©)\n",
        "# ====================================================================\n",
        "print(\"í•˜ì´ë¸Œë¦¬ë“œ Top-K ìƒì„± ì¤‘...\")\n",
        "pred_hybrid_ranking = {}\n",
        "start_time_hybrid = time.time()\n",
        "\n",
        "for idx, user_id in enumerate(users_for_ranking):\n",
        "    rated_books = set(user_train_ratings.get(user_id, {}).keys())\n",
        "    # í•„í„°ë§ëœ í›„ë³´ë§Œ ì‚¬ìš©\n",
        "    candidate_books = [bid for bid in candidate_books_filtered if bid not in rated_books]\n",
        "\n",
        "    scores = []\n",
        "    for bid in candidate_books:\n",
        "        score = predict_rating_hybrid(user_id, bid, alpha=0.6)\n",
        "        scores.append((bid, score))\n",
        "\n",
        "    scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    pred_hybrid_ranking[user_id] = [bid for bid, _ in scores[:K]]\n",
        "\n",
        "    # ì§„í–‰ë¥  í‘œì‹œ (50ëª…ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰)\n",
        "    if (idx + 1) % 50 == 0 or (idx + 1) == len(users_for_ranking):\n",
        "        print_progress(idx + 1, len(users_for_ranking), \"Hybrid\", start_time_hybrid)\n",
        "\n",
        "hybrid_time = time.time() - start_time_hybrid\n",
        "print(f\"\\nâœ“ Hybrid ì™„ë£Œ ({hybrid_time/60:.2f}ë¶„)\\n\")\n",
        "\n",
        "# ====================================================================\n",
        "# Precision & Recall ê³„ì‚°\n",
        "# ====================================================================\n",
        "print(\"Precision & Recall ê³„ì‚° ì¤‘...\")\n",
        "prec_cf, rec_cf = precision_recall_at_k(true_user2items, pred_cf_ranking, k=K)\n",
        "prec_content, rec_content = precision_recall_at_k(true_user2items, pred_content_ranking, k=K)\n",
        "prec_hybrid, rec_hybrid = precision_recall_at_k(true_user2items, pred_hybrid_ranking, k=K)\n",
        "\n",
        "print(\"\\n[Ranking ê²°ê³¼ @ K=10]\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'ëª¨ë¸':<20} {'Precision@10':>15} {'Recall@10':>15} {'ì†Œìš”ì‹œê°„':>15}\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'CF-KNN (k=30)':<20} {prec_cf:>15.6f} {rec_cf:>15.6f} {cf_time/60:>14.2f}ë¶„\")\n",
        "print(f\"{'Content-Based':<20} {prec_content:>15.6f} {rec_content:>15.6f} {content_time/60:>14.2f}ë¶„\")\n",
        "print(f\"{'Hybrid (0.6+0.4)':<20} {prec_hybrid:>15.6f} {rec_hybrid:>15.6f} {hybrid_time/60:>14.2f}ë¶„\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'ì´ ì†Œìš”ì‹œê°„':<20} {'':<15} {'':<15} {(cf_time+content_time+hybrid_time)/60:>14.2f}ë¶„\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# ====================================================================\n",
        "# ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ìš”ì•½\n",
        "# ====================================================================\n",
        "print(\"\\n[ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„]\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "models = [\n",
        "    (\"CF-KNN (k=30)\", prec_cf, rec_cf),\n",
        "    (\"Content-Based\", prec_content, rec_content),\n",
        "    (\"Hybrid (0.6+0.4)\", prec_hybrid, rec_hybrid)\n",
        "]\n",
        "\n",
        "# Precision ê¸°ì¤€ ì •ë ¬\n",
        "models_by_prec = sorted(models, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for rank, (name, prec, rec) in enumerate(models_by_prec, 1):\n",
        "    score = (prec + rec) / 2  # F1-score ê°œë…\n",
        "    print(f\"{rank}ìœ„: {name:<20} | Precision: {prec:.6f} | Recall: {rec:.6f} | F1: {score:.6f}\")\n",
        "\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# ====================================================================\n",
        "# í•„í„°ë§ ì •ë³´ ìš”ì•½\n",
        "# ====================================================================\n",
        "print(\"\\n[í•„í„°ë§ ì •ë³´]\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"ì¸ê¸°ë„ í•„í„°ë§: ìƒìœ„ 80% (í‰ê°€ ìˆ˜ >= {popularity_threshold:.0f}ê°œ)\")\n",
        "print(f\"í‰ì  í•„í„°ë§: ìƒìœ„ 90% (í‰ê·  í‰ì  >= {rating_threshold:.2f}ì )\")\n",
        "print(f\"ìµœì¢… í‰ê°€ í›„ë³´: {len(candidate_books_filtered)} / {len(all_books)} ì±… ({len(candidate_books_filtered)/len(all_books)*100:.1f}%)\")\n",
        "print(f\"ì˜ˆìƒ ì†ë„ í–¥ìƒ: {len(all_books)/len(candidate_books_filtered):.1f}ë°° ë¹ ë¦„\")\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8gP3DWt0Fmf",
        "outputId": "067efbc5-b864-4a1b-c194-9da0fbfdcaca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ìµœì¢… ìš”ì•½]\n",
            "============================================================\n",
            "ì´ ì‚¬ìš©ì: 4927\n",
            "ì´ ì±…: 8678\n",
            "ì´ ìƒí˜¸ì‘ìš©: 414113\n",
            "í‰ê·  ë°€ë„: 0.9685%\n",
            "\n",
            "[í‰ê°€ ë°©ë²•]\n",
            "1. Rating Prediction: RMSE, MAE (ì ˆëŒ€ í‰ì  ì˜ˆì¸¡ ì •í™•ë„)\n",
            "2. Ranking Evaluation: Precision@K, Recall@K (ìƒìœ„ Kê°œ ì¶”ì²œ í’ˆì§ˆ)\n",
            "\n",
            "[ì‚¬ìš©ëœ ì•Œê³ ë¦¬ì¦˜]\n",
            "1. CF-KNN: ì‚¬ìš©ì-ê¸°ë°˜ í˜‘ì—… í•„í„°ë§ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)\n",
            "2. Co ntent-Based: TF-IDF + ìˆ«ì í”¼ì²˜ (ì œëª©, ì €ì, íƒœê·¸, í‰ì , ì–¸ì–´)\n",
            "3. Hybrid: CF-KNNê³¼ Content-Basedì˜ ê°€ì¤‘í•© (Î±=0.6)\n",
            "\n",
            "[ì¶”ê°€ ì»¬ëŸ¼ í™œìš©]\n",
            "- ì €ì, ì›ì œ, íƒœê·¸ (í…ìŠ¤íŠ¸ í”¼ì²˜)\n",
            "- í‰ê·  í‰ì , í‰ì  ìˆ˜, ì¶œíŒ ì—°ë„, ì–¸ì–´ (ìˆ«ì í”¼ì²˜)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ====================================================================\n",
        "# 15ë‹¨ê³„: ìµœì¢… ìš”ì•½ ë° ê²°ë¡ \n",
        "# ====================================================================\n",
        "print(\"\\n[ìµœì¢… ìš”ì•½]\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"ì´ ì‚¬ìš©ì: {ratings_f['user_id'].nunique()}\")\n",
        "print(f\"ì´ ì±…: {ratings_f['book_id'].nunique()}\")\n",
        "print(f\"ì´ ìƒí˜¸ì‘ìš©: {len(ratings_f)}\")\n",
        "print(f\"í‰ê·  ë°€ë„: {len(ratings_f) / (ratings_f['user_id'].nunique() * ratings_f['book_id'].nunique()) * 100:.4f}%\")\n",
        "print()\n",
        "print(\"[í‰ê°€ ë°©ë²•]\")\n",
        "print(\"1. Rating Prediction: RMSE, MAE (ì ˆëŒ€ í‰ì  ì˜ˆì¸¡ ì •í™•ë„)\")\n",
        "print(\"2. Ranking Evaluation: Precision@K, Recall@K (ìƒìœ„ Kê°œ ì¶”ì²œ í’ˆì§ˆ)\")\n",
        "print()\n",
        "print(\"[ì‚¬ìš©ëœ ì•Œê³ ë¦¬ì¦˜]\")\n",
        "print(\"1. CF-KNN: ì‚¬ìš©ì-ê¸°ë°˜ í˜‘ì—… í•„í„°ë§ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)\")\n",
        "print(\"2. Co ntent-Based: TF-IDF + ìˆ«ì í”¼ì²˜ (ì œëª©, ì €ì, íƒœê·¸, í‰ì , ì–¸ì–´)\")\n",
        "print(\"3. Hybrid: CF-KNNê³¼ Content-Basedì˜ ê°€ì¤‘í•© (Î±=0.6)\")\n",
        "print()\n",
        "print(\"[ì¶”ê°€ ì»¬ëŸ¼ í™œìš©]\")\n",
        "print(\"- ì €ì, ì›ì œ, íƒœê·¸ (í…ìŠ¤íŠ¸ í”¼ì²˜)\")\n",
        "print(\"- í‰ê·  í‰ì , í‰ì  ìˆ˜, ì¶œíŒ ì—°ë„, ì–¸ì–´ (ìˆ«ì í”¼ì²˜)\")\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bigdata",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
